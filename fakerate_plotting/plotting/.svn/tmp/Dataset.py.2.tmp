"""@package Dataset
Helper class to store datasets and related quantities

@author Christian Grefe, Bonn University (christian.grefe@cern.ch)
"""

from plotting.BasicPlot import BasicPlot
from plotting.TreePlot import createHistogramFromTree, getValuesFromTree, create2DHistogramFromTree
from plotting.AtlasStyle import Style
from plotting.Cut import Cut
from plotting.HistogramStore import HistogramStore
from plotting.Tools import string2bool, overflowIntoLastBins, histToGraph,\
    progressBarInt
from plotting.Variable import createCutFlowVariable
from plotting.Systematics import SystematicVariation, SystematicsSet, TreeSystematicVariation
from plotting import DistributionTools
from copy import copy
import logging, re, os, uuid, math

def findAllFilesInPath( pattern ):
    ## helper method to resolve regular expressions in file names
    #  TChain::Add only supports wildcards in the last items, i.e. on file level.
    #  This method can resolve all wildcards at any directory level, e.g. /my/directory/a*test*/pattern/*.root
    #  @param pattern      the file name pattern using vaild python reg expressions
    #  @return list of all files matching the pattern 
    files = []
    path = ''
    items = pattern.split( '/' )
    
    def checkPath( path, items ):
        ## helper method to deal with the recursion 
        import ROOT
        if not items:
            return
        myItems = copy( items )
        item = myItems.pop(0)
        if '*' in item:
            directory = ROOT.gSystem.OpenDirectory( path )
            #DR item = item.replace( '*', '.*' )
            # DR beg and end of line control so that *truc does not match bla_truc_xyz
            item = "^"+item.replace( '*', '.*' )+"$" 
            p = re.compile( item )
            entry = True
            while entry:
                entry = ROOT.gSystem.GetDirEntry( directory )
                if p.match( entry ):
                    if not myItems:
                        files.append( path + entry )
                    else:
                        checkPath( path + entry + '/', myItems)
            ROOT.gSystem.FreeDirectory( directory )
        elif item and not myItems:
            files.append( path + item )
        else:
            checkPath( path + item + '/', myItems )
        
    checkPath( path, items )
    return files

def extractHistogramsFromRootDirectory( directory ):
    ## Helper method to collect all histogram type objects from a TDirectory, ie. a ROOT file
    #  @param directory     TDirectory object which is scanned recursively
    #  @return dictionary mapping path to histogram object
    from ROOT import gROOT, TDirectory, TH1
    histograms = {}
    directoryPath = directory.GetPath().split(':')[1]
    for key in directory.GetListOfKeys():
        className = key.GetClassName()
        classObj = gROOT.GetClass( className )
        keyName = key.GetName() 
        if classObj.InheritsFrom( TDirectory.Class() ):
            histograms.update( extractHistogramsFromRootDirectory( directory.Get( keyName ) ) )
        elif classObj.InheritsFrom( TH1.Class() ):
            histograms[ os.path.join( directoryPath, keyName ) ] = directory.Get( keyName )
        else:
            pass
    return histograms

class SumOfWeightsCalculator( object ):
    ## Helper class to wrap sum of weight calculation
    
    def __init__( self ):
        ## Default constructor
        self.sumOfWeights = 0.
        self.calculated = False
        
    def calculate( self, dataset ):
        ## Calculate the sum of weights for the given dataset
        #  @param dataset     input dataset
        #  @return the sum of weights 
        return 0
    

class HistogramBasedSumOfWeightsCalculator( SumOfWeightsCalculator ):
    ## Helper class to wrap sum of weight calculation
    
    def __init__( self, histogramName='h_metadata', binIndex=7 ):
        ## Default constructor
        SumOfWeightsCalculator.__init__( self )
        self.histogramName = histogramName
        self.binIndex = int(binIndex)
    
    def calculate( self, dataset ):
        ## Calculate the sum of weights for the given dataset
        #  @param dataset     input dataset
        #  @return the sum of weights
        if self.calculated:
            return self.sumOfWeights
        self.sumOfWeights = 0.
        from ROOT import TFile
        for fileNamePattern in dataset.fileNames:
            for fileName in findAllFilesInPath( fileNamePattern ):
                rootFile = TFile.Open( fileName )
                if rootFile and rootFile.IsOpen():
                    h = rootFile.Get( self.histogramName )
                    if h:
                        self.sumOfWeights += h.GetBinContent( self.binIndex )
                    rootFile.Close()
        # protect for floating point precision to avoid tiny sum of weights
        if abs(self.sumOfWeights) < 1e-09:
            self.sumOfWeights = 0
        self.calculated = True
        return self.sumOfWeights

class FriendTree( object ):
    ## container class to store friend tree
    logger = logging.getLogger( __name__ + '.FriendTree' )
    
    def __init__( self, treeName, fileNames, alias='', systematicVariations=[] ):
        ## Default constructor
        #  @param fileNames        list of fileNames
        #  @param treeName         name of the friend tree in the files
        #  @param alias            alias of the friend tree (use in case of clash with main tree)
        #  @systematicVariation    define for which tree systematics this friend tree should be used (empty list is used for all)
        self.fileNames = fileNames
        self.treeName = treeName
        self.alias = alias
        self.systematicVariations = systematicVariations
        self.tree = None
        
    def _open( self ):
        ## Helper method to open all files
        from ROOT import TChain
        self.tree = TChain( self.treeName )
        nFiles = 0
        for fileNamePattern in self.fileNames:
            for fileName in findAllFilesInPath( fileNamePattern ):
                nFiles += self.tree.Add( fileName )
        if nFiles:
            # update the estimate for this TChain, needed for proper use of GetSelectedRows
            self.tree.SetEstimate( self.tree.GetEntries() + 1 )
            self.logger.debug( '_open(): opened %d files with %d entries from %r' % ( nFiles, self.tree.GetEntries(), self.fileNames ) )
        else:
            self.logger.warning( '_open(): found no files for %r in %r' % ( self, self.fileNames ) )
            
    def addTo( self, tree ):
        ## Add this tree as a friend to the given tree
        treeName = tree.GetName()
        
        # check if this tree is a suitable friend for this systematic variation
        if self.systematicVariations:
            use = False
            for variation in self.systematicVariations:
                if treeName == variation.treeName:
                    use = True
                    break
            if not use:
                return
        
        if not self.tree:
            self._open()
        if not self.tree:
            return
        self.logger.error( '_addTo(): adding "%s" as friend tree to "%s"' % ( self.treeName, treeName ) )
        tree.AddFriend( self.tree, self.alias )
        
# store all available datasets
DATASETS={}   

class Dataset( object ):
    ## Container class for a dataset and associated information. Datasets are opened as TChains
    defaultHistogramStore = None
    defaultSumOfWeightsCalculator = HistogramBasedSumOfWeightsCalculator()
    logger = logging.getLogger( __name__ + '.Dataset' )
    
    def __init__( self, name, title='', fileNames=[], treeName='NOMINAL', style=None, weightExpression=None, crossSection=1., kFactor=1., isData=False, isSignal=False, isBSMSignal=False ):
        ## Default contructor
        #  @param name               name of the dataset used for output file names
        #  @param title              title used for example in legend entries (use TLatex here)
        #  @param fileNames          list of input file names belonging to this dataset
        #  @param treeName           name of the ROOT tree in each file
        #  @param style              default Style object associated with this dataset
        #  @param weight             default weight expression for this dataset
        #  @param crossSection       sets the crossSection (in pb)
        #  @param kFactor            correction factor applied as scaling to all histograms
        #  @param isData             this is data (not MC) no scale factors will be applied to histograms
        #  @param isSignal           this is signal MC, simply stored to decide how it is used in MVA training
        #  @param isBSMSignal        this is BSM signal MC (can be useful to separate from SM signal)
        self.openTrees = {}
        self.keepTreesInMemory = True
        self.treeEntryLists = {}
        self.name = name
        self.scaleFactors = {}
        self.title = title if title else name
        self.style = style 
        self.weightExpression = weightExpression
        self.sumOfWeights = 0.
        self.crossSection = crossSection
        self.kFactor = kFactor
        self.fileNames = fileNames if fileNames else []
        self.friendTrees = []
        self.isData = isData
        self.isSignal = isSignal
        self.isBSMSignal = isBSMSignal
        self.ignoreCuts = []
        self.addCuts = []
        self.histogramStore = self.defaultHistogramStore
        self.sumOfWeightsCalculator = copy( self.defaultSumOfWeightsCalculator )
        self.systematicsSet = SystematicsSet()
        self.nominalSystematics = TreeSystematicVariation( 'nominal', 'Nominal', treeName )
        self.preselection = Cut()
        
        # store in the list of all datasets
        self._register()
        
    def copy( self, name, title):
        ## create a copy of this dataset with the given name and title
        #  @param name               name of the dataset copy used for output file names
        #  @param title              title used for example in legend entries (use TLatex here)
        #  @return the copied dataset
        dataset = copy( self )
        dataset.name = name
        dataset.title = title
        # explicit copies of contained lists and dictionaries to avoid clashes
        dataset.openTrees = self.openTrees.copy()
        dataset.friendTrees = copy(self.friendTrees)
        dataset.scaleFactors = self.scaleFactors.copy()
        dataset.fileNames = copy(self.fileNames)
        dataset.ignoreCuts = copy(self.ignoreCuts)
        dataset.addCuts = copy(self.addCuts)
        dataset.systematicsSet = copy(self.systematicsSet)
        return dataset

    @classmethod
    def fromString( cls, s ):
        ## Contructor from string used to read in text files
        #  Format is "name; title; treeName; color; crossSection; kFactor; fileName1, fileName2, ... "
        result = [ x.lstrip().rstrip() for x in s.split( ';' ) ]
        name = result[0] if len(result) > 0 else 'DataSet'
        title = result[1] if len(result) > 1 else None
        treeName = result[2] if len(result) > 2 else 'NOMINAL'
        lineColor = int(result[3]) if len(result) > 3 else 0
        crossSection = float(result[4]) if len(result) > 4 else 1.
        kFactor = float(result[5]) if len(result) > 5 else 1.
        fileNamesString = result[6] if len(result) > 6 else ''
        fileNames = [ x.strip() for x in fileNamesString.split( ',' ) ]
        return cls( name, title, fileNames, treeName, Style(lineColor), crossSection=crossSection, kFactor=kFactor )

    @classmethod
    def fromXML( cls, element ):
        ## Constructor from an XML element
        #  <Dataset name="" title="" treeName="" isData="" isSignal="" crossSection="" kFactor="">
        #    <Style color="5"/>
        #    <File> File1 </File>
        #    <File> File2 </File>
        #    <AddCuts>
        #      <Cut> Cut1 </Cut>
        #      <Cut> Cut2 </Cut>
        #    </AddCuts>
        #    <IgnoreCuts>
        #      <Cut> Cut3 </Cut>
        #      <Cut> Cut4 </Cut>
        #    </IgnoreCuts>
        #  </Dataset>
        #  @param element    the XML element
        #  @return the HistogramStore object
        attributes = element.attrib
        name = attributes[ 'name' ]
        if DATASETS.has_key( name ):
            return DATASETS[name]
        dataset = cls( name )
        if attributes.has_key( 'title' ):
            dataset.title = attributes['title']
        if attributes.has_key( 'treeName' ):
            dataset.treeName = attributes['treeName']
        if attributes.has_key( 'isData' ):
            dataset.isData = string2bool(attributes['isData'])
        if attributes.has_key( 'isSignal' ):
            dataset.isSignal = string2bool(attributes['isSignal'])
        if attributes.has_key( 'isBSMSignal' ):
            dataset.isBSMSignal = string2bool(attributes['isBSMSignal'])
        if attributes.has_key( 'crossSection' ):
            dataset.crossSection = float(attributes['crossSection'])
        if attributes.has_key( 'kFactor' ):
            dataset.kFactor = float(attributes['kFactor'])
        if attributes.has_key( 'weightExpression' ):
            dataset.weightExpression = attributes['weightExpression']
        dataset.style = Style.fromXML( element.find( 'Style' ) ) if element.find( 'Style' ) is not None else None
        for fileElement in element.findall( 'File' ):
            dataset.fileNames.append( fileElement.text.strip() )
        if element.find( 'AddCuts' ):
            for cutElement in element.find( 'AddCuts' ).findall( 'Cut' ):
                dataset.addCuts.append( Cut.fromXML( cutElement ) )
        if element.find( 'IgnoreCuts' ):
            for cutElement in element.find( 'IgnoreCuts' ).findall( 'Cut' ):
                dataset.ignoreCuts.append( Cut.fromXML( cutElement ) )
        return dataset
        
    def __repr__( self ):
        return 'Dataset(%s)' % self.name
    
    def __str__( self ):
        return 'Dataset(%s): XS=%g pb, effXS=%g pb, sF=%r' % (self.name, self.crossSection, self.effectiveCrossSection, self.scaleFactors)

    def _register( self ):
        ## Helper method to register this Dataset with the store
        if DATASETS.has_key( self.name ):
            self.logger.warning( '_register(): trying to register a Dataset with an already existing name: "%s"' % self.name )
        else:
            DATASETS[ self.name ] = self

    def _open( self, treeName=None ):
        ## Read the files into the TChain. Automatically called when trying to create a histogram
        if not treeName:
            treeName = self.nominalSystematics.treeName
        if self.openTrees.has_key( treeName ):
            return self.openTrees[ treeName ]
        from ROOT import TChain
        tree = TChain( treeName )
        nFiles = 0
        for fileNamePattern in self.fileNames:
            for fileName in findAllFilesInPath( fileNamePattern ):
                nFiles += tree.Add( fileName )
        if nFiles:
            result = self.sumOfWeightsCalculator.calculate( self )
            if result:
                self.sumOfWeights = result
            # update the estimate for this TChain, needed for proper use of GetSelectedRows
            tree.SetEstimate( tree.GetEntries() + 1 )
            if self.keepTreesInMemory:
                self.openTrees[ treeName ] = tree
            self._applyPreselectionToTree( tree )
            self.logger.debug( '_open(): opened %d files with %d entries from %r' % ( nFiles, tree.GetEntries(), self.fileNames ) )
            # add friend trees
            for friend in self.friendTrees:
                friend.addTo( tree )
        else:
            self.logger.warning( '_open(): found no files for %r in %r' % ( self, self.fileNames ) )
        return tree
    
    def _close( self, treeName ):
        if self.openTrees.has_key( treeName ):
            del self.openTrees[ treeName ]
        
    def _applyPreselectionToTree( self, tree ):
        ## helper method to apply preselection using TEntryList
        treeName = tree.GetName()
        selection = self.preselection.cut
        listName = 'entryList_%s_%s' % ( treeName, self.name ) 
        
        entryList = None
        if tree.GetEntryList():
            # we already had set an entry list, replace with NULL
            tree.SetEntryList( 0 )
            self.logger.debug( '_applyPreselectionToTree(): removing preselection for %s in %r' % ( tree, self ) )
        if not selection:
            # nothing to select simply return
            return
        if self.treeEntryLists.has_key( treeName ):
            entryList = self.treeEntryLists[ treeName ]
        else:
            tree.Draw( '>>' + listName, selection, 'entrylist' )
            from ROOT import gDirectory
            entryList = gDirectory.Get( listName )
            self.treeEntryLists[ treeName ] = entryList
            
        if entryList:
            tree.SetEntryList( entryList )
            
    def _determineCut( self, cut ):
        ## helper method to determine the cut to use
        cut = Cut() + cut
        for ignoredCut in self.ignoreCuts:
            cut = cut.withoutCut( ignoredCut )
        for addedCut in self.addCuts:
            cut += addedCut
        return cut
    
    @property
    def combinedScaleFactors( self ):
        ## get the product of all global scale factors including factors from systematics
        return self.getCombinedScaleFactors()
    
    @property 
    def crossSection( self ):
        ## Get the cross section in pb
        return self.__crossSection
    
    @crossSection.setter 
    def crossSection( self, value ):
        ## Set the cross section in pb
        self.scaleFactors['crossSection'] = value
        self.__crossSection = value
        
    @property 
    def kFactor( self ):
        ## Get the kFactor
        return self.__kFactor
    
    @kFactor.setter 
    def kFactor( self, value ):
        ## Set the kFactor
        self.scaleFactors['kFactor'] = value
        self.__kFactor = value
    
    @property
    def combinedSystematicsSet( self ):
        ## Get the SystematicsSet
        return self.systematicsSet
       
    @property 
    def systematicsSet( self ):
        ## Get the SystematicsSet
        return self.__systematicsSet
    
    @systematicsSet.setter 
    def systematicsSet( self, value ):
        ## Set the SystematicsSet
        self.__systematicsSet = value
    
    @property
    def effectiveCrossSection( self ):
        ## Get the effective cross section in pb including scale factors
        return self.combinedScaleFactors
    
    @property
    def weightExpression( self ):
        ## Get the weight expression applied to this Dataset
        return self.__weightExpression
    
    @weightExpression.setter
    def weightExpression( self, expression ):
        ## Set the weight expression
        self.__weightExpression = expression
    
    @property
    def entries( self ):
        ## Get the number of entries in the dataset
        tree = self._open( self.nominalSystematics.treeName )
        return tree.GetEntries()
    
    @property
    def trueDatasets( self ):
        ## Get list of all contained datasets
        #  Recursively resolves all PhysicsProcess daughters, only returns Dataset objects
        return [self]
    
    @property
    def preselection( self ):
        ## Get the preselection cut currently applied
        return self._preselection
    
    @preselection.setter
    def preselection( self, cut=Cut() ):
        ## Define a preselection for this dataset using the TEntryList functionality of TTree
        #  Use an empty cut to reset the preselection
        #  WARNING: this selection is always active even if a looser selection is drawn
        #  @param cut    the preselection cut to apply
        self._preselection = cut
        # remove all stored TEntryLists
        self.treeEntryLists.clear()
        # apply the preselection to all open trees
        for tree in self.openTrees.itervalues():
            self._applyPreselectionToTree( tree )
    
    def addSystematics( self, systematics ):
        ## Add a Systematics object to this Dataset
        try:
            self.systematicsSet |= systematics
        except TypeError:
            self.systematicsSet.add( systematics )
            
    def addFriendTree( self, friendTree ):
        ## Add a FriendTree object to this dataset
        self.friendTrees.append( friendTree )
        
    def removeSystematics( self, systematics ):
        ## Remove a Systematics object from this Dataset
        self.systematicsSet.discard( systematics )
    
    def getCombinedScaleFactors( self, systematicVariation=None ):
        ## Get the product of all scale factors including systematics
        #  @param systematicVariation      use the scale factor from the systematicVariation instead of the respective nominal
        #  @return product of all scale factors
        product = 1.0
        for value in self.scaleFactors.itervalues():
            product *= value
        return product * self.systematicsSet.totalScaleFactor( systematicVariation )
        
    def save( self, fileName, selection=None ):
        ## Store this dataset into a single ROOT file. The given selection is applied.
        #  All trees registered in the SystematicsSet are stored. In addition, all histogram objects found
        #  are added up and stored in the output file.
        #  @param fileName      name of the output file
        #  @param selection     event selection applied to the trees (default preselection if defined)
        if selection is None:
            selection = self.preselection.cut if self.preselection else ''
        from ROOT import TFile
        outputFile = TFile.Open( fileName, 'RECREATE' )
        if not outputFile or not outputFile.IsOpen():
            self.logger.error( 'save(): unable to open output file at "%s"' % fileName )
            return
        # copy all trees connected to any systematics
        treeNames = self.systematicsSet.treeNames
        treeNames.add( self.nominalSystematics.treeName )
        nTrees = len( treeNames )
        self.logger.info( 'save(): storing %d trees with selection="%s" in %s' % ( nTrees, selection, fileName ) )
        for index, treeName in enumerate( sorted( treeNames ) ):
            tree = self._open( treeName )
            if not tree.GetEntries():
                continue
            outputFile.cd()
            progressBarInt( index, nTrees, 'Writing: ' + treeName )
            newtree = tree.CopyTree( selection )
            newtree.Write()
            self.logger.debug( 'save(): selected %d/%d entries from %s' % ( newtree.GetEntries(), tree.GetEntries(), treeName ) )
        progressBarInt( nTrees, nTrees, 'Done' )
        # now get all histogram objects and add them together
        histograms = {}
        for fileNamePattern in self.fileNames:
            for fileName in findAllFilesInPath( fileNamePattern ):
                rootFile = TFile.Open( fileName )
                if rootFile and rootFile.IsOpen():
                    for path, hist in extractHistogramsFromRootDirectory( rootFile ).items():
                        if histograms.has_key( path ):
                            histograms[path].Add( hist )
                        else:
                            outputFile.cd()
                            histograms[path] = hist.Clone( '%s_%s' % (hist.GetName(), uuid.uuid1() ) )
                    rootFile.Close()
        # store the histograms in the output file
        self.logger.debug( 'save(): storing %d histograms' % ( len( histograms ) ) )
        for path in sorted( histograms.keys() ):
            hist = histograms[path]
            outputFile.cd()
            path, name = os.path.split( path )
            if not outputFile.GetDirectory( path ):
                outputFile.mkdir( path )
            outputFile.cd( path )
            hist.Write( name )
        outputFile.Close()
    
    def getYield( self, cut=Cut(), weightExpression=None, luminosity=1., ignoreWeights=False, systematicVariation=None, ignoreDataWeight=False ):
        ## Calculate the expected yield for the given selection
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param ignoreDataWeight     used for fake-factor data-mc where weight is to be applied to data via self.weightExpression
        #  @param ignoreWeights        ignore the weights and any other scale factors including luminosity
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @return the (yield, uncertainty)
        systematicVariation = systematicVariation if systematicVariation else self.nominalSystematics
        tree = self._open( systematicVariation.treeName )
        if not tree:
            return
        weightExpression = weightExpression if weightExpression else self.weightExpression
        if ignoreDataWeight and self.isData:
            weightExpression = self.weightExpression
        selection = cut.cut if ignoreWeights else ( self._determineCut(cut) * weightExpression * self.systematicsSet.totalWeight( systematicVariation ) ).cut
        expression = selection
        if ignoreWeights:
            scaleFactor = 1
        else:
            scaleFactor = self.getCombinedScaleFactors( systematicVariation )
            if luminosity and not self.isData:
                scaleFactor *= luminosity
            if self.sumOfWeights and not self.isData:
                scaleFactor /= self.sumOfWeights
        if not expression:
            if tree.GetEntryList():
                return tree.GetEntryList().GetN() * scaleFactor
            return self.entries * scaleFactor
        weights = getValuesFromTree( tree, expression, selection )[1]
        # FIXME: this is actually not correct, need to treat it as efficiency
        totalYield, uncertainty = DistributionTools.sumOfWeights( weights )
        self.logger.debug( 'getYield(): total yield=%g, total SF=%g' % (totalYield, scaleFactor) )
        return totalYield * scaleFactor, uncertainty * scaleFactor
    
    def getValues( self, xVar, cut=None, weightExpression=None, luminosity=1., systematicVariation=None ):
        ## Gets the values and weights for a given variable and selection
        #  @param xVar                 Variable object defining which values should be calculated
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @return (values, weights)
        weightExpression = weightExpression if weightExpression else self.weightExpression
        systematicVariation = systematicVariation if systematicVariation else self.nominalSystematics
        cut = self._determineCut( cut )
        self.logger.debug( 'getValues(): getting values for %r with cut=%r and sytematics=%r from %r' % (xVar, cut, systematicVariation, self) )
        tree = self._open( systematicVariation.treeName )
        if not tree:
            return
        values, weights = getValuesFromTree( tree, xVar.command, cut.cut )
        sF = self.getCombinedScaleFactors( systematicVariation )
        if not self.isData:
            sF *= luminosity
        return values, weights * sF
    
    def getHistogram( self, xVar, title=None, cut=None, weightExpression=None, drawOption='', style=None, luminosity=1., recreate=False, systematicVariation=None, includeOverflowBins=False, ignoreDataWeight=False ):
        ## Wrapper for TTree::Draw on the TChain object
        #  If a HistogramStore is defined it will first try to find the histogram in the store. If it does not exist the histogram will be
        #  created as usual and afterwards placed in the HistogramStore. Scale factor, cross section and kFactor are not persisted and always
        #  applied in this command.    The "recreate" option allows to override existing histograms if they are already in the HistogramStore. 
        #  @param xVar                 Variable object that defines the variable expression used in draw and the binning
        #  @param title                defines the histogram title
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param drawOption           ROOT draw option
        #  @param style                Style object (overrides the default style object)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param recreate             force recreation of the histogram (don't read it from a possible histogram file)
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param ignoreDataWeight     used for fake-factor data-mc where weight is to be applied to data via self.weightExpression
        #  @param includeOverflowBins  decide if the entries of the overflow bins should be added to the first and last bins, respectively
        #  @return histogram
        
        self.logger.debug( 'getHistogram(): creating histogram for var=%r with cut=%r and syst=%r from %r' % (xVar, cut, systematicVariation, self) )
        
        title = title if title else self.title
        style = style if style else self.style
        weightExpression = weightExpression if weightExpression else self.weightExpression
        if ignoreDataWeight and self.isData:
            weightExpression = self.weightExpression
        systematicVariation = systematicVariation if systematicVariation else self.nominalSystematics
        cut = self._determineCut( cut )
        
        # try to get the histogram from the store
        hist = None

        storeSystematicsName = systematicVariation.name if systematicVariation.isShapeSystematics else self.nominalSystematics.name
        if self.histogramStore:
            hist = self.histogramStore.getHistogram( xVar.title, self.name, storeSystematicsName, xVar, cut )
        
        # create the histogram if necessary
        if not hist or recreate:
            tree = self._open( systematicVariation.treeName )
            if not tree:
                return
            # include the weights from systematics
            weightExpression *= self.systematicsSet.totalWeight( systematicVariation )
            hist = createHistogramFromTree( tree, xVar, title, cut, weightExpression, drawOption, style )
            if hist and self.sumOfWeights and hist.Integral(0, hist.GetNbinsX()+1) and not self.isData:
                hist.Scale( 1. / self.sumOfWeights )
                self.logger.debug( 'getHistogram(): dividing by sum of weights %g, yield=%g' % (self.sumOfWeights, hist.Integral()) )
            if self.histogramStore:
                self.histogramStore.putHistogram( xVar.title, self.name, storeSystematicsName, xVar, cut, hist )
        
        # apply scale factors
        if hist:
            sF = self.getCombinedScaleFactors( systematicVariation )
            if not self.isData:
                sF *= luminosity
            hist.Scale( sF )
            self.logger.debug( 'getHistogram(): scaling histogram by %g, total yield=%g' % (sF, hist.Integral()) )
            if includeOverflowBins:
                self.logger.debug( 'getHistogram(): moving overflow entries into first/last bins' )
                hist = overflowIntoLastBins( hist )
        # apply styling
        if style and hist:
            style.apply( hist )
        return hist
    
    def getHistogram2D( self, xVar, yVar, title=None, cut=None, weightExpression=None, style=None, luminosity=1., recreate=False, systematicVariation=None, profile=False ):
        ## Wrapper for TTree::Draw on the TChain object
        #  If a HistogramStore is defined it will first try to find the histogram in the store. If it does not exist the histogram will be
        #  created as usual and afterwards placed in the HistogramStore. Scale factor, cross section and kFactor are not persisted and always
        #  applied in this command.    The "recreate" option allows to override existing histograms if they are already in the HistogramStore. 
        #  @param xVar                 Variable object that defines the variable expression for x used in draw and the binning
        #  @param yVar                 Variable object that defines the variable expression for y used in draw and the binning
        #  @param title                defines the histogram title
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param style                Style object (overrides the default style object)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param recreate             force recreation of the histogram (don't read it from a possible histogram file)
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param profile      Decide if a TProfile should be created instead of a TH2
        #  @return histogram
        
        self.logger.debug( 'getHistogram(): creating histogram for xVar=%r and yVar=%r with cut=%r and syst=%r from %r' % (xVar, yVar, cut, systematicVariation, self) )
        
        title = title if title else self.title
        style = style if style else self.style
        weightExpression = weightExpression if weightExpression else self.weightExpression
        systematicVariation = systematicVariation if systematicVariation else self.nominalSystematics
        cut = self._determineCut( cut )
        
        #FIXME: try to get histogram from HistogramStore first
        
        tree = self._open( systematicVariation.treeName )
        if not tree:
            return
        hist = create2DHistogramFromTree( tree, xVar, yVar, title, cut, weightExpression, profile )
        if hist and self.sumOfWeights and hist.Integral() and not self.isData:
            hist.Scale( 1. / self.sumOfWeights )
            self.logger.debug( 'getHistogram2D(): dividing by sum of weights %g, yield=%g' % (self.sumOfWeights, hist.Integral()) )
        
        # apply scale factors
        if hist:
            sF = self.getCombinedScaleFactors( systematicVariation )
            if not self.isData:
                sF *= luminosity
            hist.Scale( sF )
            self.logger.debug( 'getHistogram2D(): scaling histogram by %g, total yield=%g' % (sF, hist.Integral()) )
        # apply styling
        if style and hist:
            style.apply( hist )
        return hist
        
    def getSystematicsGraph( self, xVar, title=None, cut=None, weightExpression=None, drawOption='', style=None, luminosity=1., recreate=False, includeOverflowBins=False ):
        ## Creates a graph similar to getHistogram. The errors are determined from the combined systematic uncertainties.
        #  Loops over all systematics and determines the respective uncertainties. Uncertainties are combined in quadrature.
        #  @param xVar                 Variable object that defines the variable expresseion used in draw and the binning
        #  @param title                defines the histogram title
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param drawOption           ROOT draw option
        #  @param style                Style object (overrides the default style object)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param recreate             force recreation of the histogram (don't read it from a possible histogram file)
        #  @param includeOverflowBins  decide if the entries of the overflow bins should be added to the first and last bins, respectively
        #  @return graph
        title = title if title else self.title
        style = style if style else self.style
        weightExpression = weightExpression if weightExpression else self.weightExpression
        
        from ROOT import TGraphAsymmErrors
        nominalHist = self.getHistogram( xVar, title, cut, weightExpression, drawOption, style, luminosity, recreate, None, includeOverflowBins )
        graph = histToGraph( nominalHist, '%s_syst' % nominalHist.GetName(), False )
            
        for systematics in self.combinedSystematicsSet:
            # TODO: instead of simply summing up in quadrature we could include correlation terms (at least within each bin)
            upHist = self.getHistogram( xVar, title, cut, weightExpression, drawOption, style, luminosity, recreate, systematics.up, includeOverflowBins )
            downHist = self.getHistogram( xVar, title, cut, weightExpression, drawOption, style, luminosity, recreate, systematics.down, includeOverflowBins )
            for i in xrange( nominalHist.GetNbinsX() ):
                upVal = upHist.GetBinContent( i+1 )
                downVal = downHist.GetBinContent( i+1 )
                nominalVal = nominalHist.GetBinContent( i+1 )
                deltaUp = upVal - nominalVal
                deltaDown = downVal - nominalVal
                # check which value is the down fluctuation
                if deltaDown > deltaUp:
                    deltaDown, deltaUp = deltaUp, deltaDown
                # add uncertainty in quadrature to previous uncertainties
                graph.SetPointEYlow( i, math.sqrt(graph.GetErrorYlow( i )**2 + deltaDown**2) )
                graph.SetPointEYhigh( i, math.sqrt(graph.GetErrorYhigh( i )**2 + deltaUp**2) )
        # apply styling
        if style and graph:
            style.apply( graph )
        return graph
    
    def getResolutionGraph( self, xVar, yVar, title=None, measure=None, cut='', weightExpression='', style=None, luminosity=1., recreate=False, systematicVariation=None ):
        ## Create and fill a resolution graph for this dataset, i.e. resolution of y vs. x
        #  @param xVar                 defines the x axis. The binning defines the slicing for different resolution evaluation
        #  @param yVar                 variable for which the resolution is determined 
        #  @param title                title of the graph
        #  @param measure              Measure object to evaluate the resolution (see plotting/ResolutionGraph.py)
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param style                Style object (overrides the default style object)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param recreate             force recreation of the histogram (don't read it from a possible histogram file)
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @return the filled graph
        self.logger.debug( 'getResolutionGraph(): creating resolution graph for yVar=%r, xVar=%r with cut=%r and syst=%r from %r' % (yVar, xVar, cut, systematicVariation, self) )
        
        bins = xVar.binning.bins
        title = '%s vs %s' % (yVar.title, xVar.title) if title is None else title
        name = 'g%s_%s' % ( title.replace(' ', '_').replace('(', '').replace(')',''), uuid.uuid1() )
        style = style if style else self.style
        weightExpression = weightExpression if weightExpression else self.weightExpression
        systematicVariation = systematicVariation if systematicVariation else self.nominalSystematics
    
        from ROOT import TGraphAsymmErrors
        graph = TGraphAsymmErrors( xVar.binning.nBins )
        graph.SetNameTitle( name, title )
        
        yMean, yErrLow, yErrUp = (0., 0., 0.)
        for iBin in xrange( xVar.binning.nBins ):
            low = bins[iBin]
            up = bins[iBin+1]
            xMean = low + 0.5 * (up - low)
            xErr = xMean - low
            myCut = Cut( '%s >= %s && %s < %s' % (xVar.command, low, xVar.command, up) ) + cut + yVar.defaultCut
            values, weights = self.getValues( yVar, myCut, weightExpression, luminosity, systematicVariation )
            if measure:
                yMean, yErrLow, yErrUp = measure.calculateFromValues( values, weights )
            else:
                yMean, yErrLow, yErrUp = ( 0., 0., 0. )
            graph.SetPoint( iBin, xMean, yMean )
            graph.SetPointError( iBin, xErr, xErr, yErrLow, yErrUp )
        
        if graph and style:
            style.apply( graph )
        return graph

    def getCutFlowYields( self, cuts, luminosity=None, ignoreWeights=False, systematicVariation=None, accumulateCuts=True ):
        ## Create a dictionary of cuts with their corresponding yields
        #  @param cuts                 list of cuts to apply
        #  @param luminosity           global scale factor
        #  @param ignoreWeights        ignore the weights and any other scale factors including luminosity
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param accumulateCuts       decide if the cuts should be successively combined, ie. second cut applied in addition to first etc.
        #  @return dictionary of cut to yield
        result = {}
        myCut = Cut()
        for cut in cuts:
            if accumulateCuts:
                myCut += cut
            else:
                myCut = cut
            result[cut] = self.getYield( myCut, luminosity=luminosity, ignoreWeights=ignoreWeights, systematicVariation=systematicVariation )
        return result
            
    def getCutflowHistogram( self, cuts, luminosity=None, ignoreWeights=False, cutFlowVariable=None, systematicVariation=None, accumulateCuts=True ):
        ## Create and fill a cutflow histogram for this dataset
        #  @param cuts                 list of cuts to apply
        #  @param luminosity           global scale factor
        #  @param ignoreWeights        ignore the weights and any other scale factors including luminosity
        #  @param cutFlowVariable      use a previously defined variable instead
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param accumulateCuts       decide if the cuts should be successively combined, ie. second cut applied in addition to first etc.
        #  @return the filled histogram
        var = cutFlowVariable if cutFlowVariable else createCutFlowVariable( cuts=cuts )
        hist = var.createHistogram( self.title )
        yields = self.getCutFlowYields( cuts, luminosity, ignoreWeights, systematicVariation, accumulateCuts )
        for index, cut in enumerate( cuts ):
            y, uncertainty = yields[cut]
            hist.SetBinContent( index+1, y )
            hist.SetBinError( index+1, uncertainty )
        if hist and self.style:
            self.style.apply( hist )
        return hist

    def toString( self ):
        ## String representation used for persistency
        s = '%s; %s; %s; %d; %g; %g; ' % ( self.name, self.title, self.nominalSystematics.treeName, self.style.lineColor, self.crossSection, self.kFactor )
        for fileName in self.fileNames:
            s += '%s, ' % fileName
        s = s.rstrip(', ')
        return s
    
# store all defined processes
PHYSICSPROCESSES={}
    
class PhysicsProcess( Dataset ):
    ## Container class for a set of datasets that should be treated together
    #  Fulfills Dataset interface so it can be nested, i.e. contain other PhysicsProcesses
    logger = logging.getLogger( __name__ + '.PhysicsProcess' )
    
    def __init__( self, name, title='', style=None, kFactor=1.0, isData=False, isSignal=False, isBSMSignal=False, datasets=None ):
        ## Default contructor
        #  @param name               name of the physics process used for output file names
        #  @param title              title used for example in legend entries (use TLatex here)
        #  @param style              default Style object associated with this physics process
        #  @param kFactor            correction factor applied as scaling to all histograms
        #  @param isData             this is data (not MC), simply for book keeping
        #  @param isSignal           this is signal MC, simply stored to decide how it is used in MVA training
        #  @param isBSMSignal        this is BSM signal MC, in case that is different from the ordinary signal
        #  @param datasets           list of datasets in this physics process
        self.datasets = []
        Dataset.__init__( self, name, title, None, None, style, None, None, kFactor, isData, isSignal, isBSMSignal )
        self.datasets = datasets if datasets else []
    
    def copy( self, name, title ):
        ## Create a copy of this PhysicsProcess with the given name and title
        #  This does NOT copy underlying datasets, take special care when modifying those
        #  @param name               name of the physics process copy used for output file names
        #  @param title              title used for example in legend entries (use TLatex here)
        #  @return the copied physics process
        process = Dataset.copy( self, name, title )
        process.datasets = copy(self.datasets)
        return process
        
    @classmethod
    def fromString( cls, s ):
        ## Contructor from string used to read in text files
        #  Format is "name; title; color; kFactor; dataset1, dataset2, ... "
        result = [x.lstrip().rstrip() for x in s.split( ';' )]
        name = result[0] if len(result) > 0 else 'PhysicsProcess'
        title = result[1] if len(result) > 1 else None
        lineColor = int(result[2]) if len(result) > 2 else 0
        kFactor = float(result[3]) if len(result) > 3 else 1.
        datasetsString = result[4] if len(result) > 4 else ''
        datasetStrings = datasetsString.split( ',' )
        datasets = []
        for datasetString in datasetStrings:
            datasetName = datasetString.strip()
            if not datasetName:
                continue
            if DATASETS.has_key( datasetName ):
                datasets.append( DATASETS[ datasetName ] )
            else:
                cls.logger.error( 'fromString(): Unknown dataset "%s"' % datasetName )
        return cls( name, title, Style(lineColor), kFactor, datasets )
    
    @classmethod
    def fromXML( cls, element ):
        ## Constructor from an XML element
        #  <Dataset name="" title="" isData="" isSignal="" kFactor="">
        #    <Style color="5"/>
        #    <Dataset name=""/>
        #    <PhysicsProcess name=""/>
        #    <AddCuts>
        #      <Cut> Cut1 </Cut>
        #      <Cut> Cut2 </Cut>
        #    </AddCuts>
        #    <IgnoreCuts>
        #      <Cut> Cut3 </Cut>
        #      <Cut> Cut4 </Cut>
        #    </IgnoreCuts>
        #  </Dataset>
        #  @param element    the XML element
        #  @return the HistogramStore object
        attributes = element.attrib
        name = attributes[ 'name' ]
        if PHYSICSPROCESSES.has_key( name ):
            return PHYSICSPROCESSES[name]
        process = cls( name )
        if attributes.has_key( 'title' ):
            process.title = attributes['title']
        if attributes.has_key( 'isData' ):
            process.isData = string2bool(attributes['isData'])
        if attributes.has_key( 'isSignal' ):
            process.isSignal = string2bool(attributes['isSignal'])
        if attributes.has_key( 'isBSMSignal' ):
            process.isBSMSignal = string2bool(attributes['isBSMSignal'])
        if attributes.has_key( 'kFactor' ):
            process.kFactor = float(attributes['kFactor'])
        process.style = Style.fromXML( element.find( 'Style' ) ) if element.find( 'Style' ) is not None else None
        for datasetElement in element.findall( 'Dataset' ):
            process.datasets.append( Dataset.fromXML(datasetElement) )
        for processElement in element.findall( 'PhysicsProcess' ):
            process.datasets.append( Dataset.fromXML(processElement) )
        if element.find( 'AddCuts' ) is not None:
            for cutElement in element.find( 'AddCuts' ).findall( 'Cut' ):
                process.addCuts.append( Cut.fromXML( cutElement ) )
        if element.find( 'IgnoreCuts' ) is not None:
            for cutElement in element.find( 'IgnoreCuts' ).findall( 'Cut' ):
                process.ignoreCuts.append( Cut.fromXML( cutElement ) )
        return process
    
    def __repr__( self ):
        return 'PhysicsProcess(%s)' % self.name
    
    def __str__( self ):
        return '%s, %s' % (Dataset.__str__(self), self.datasets)
    
    def _register( self ):
        ## Helper method to register this Dataset with the store
        if PHYSICSPROCESSES.has_key( self.name ):
            self.logger.warning( '_register(): trying to register a PhysicsProcess with an already existing name: "%s"' % self.name )
        else:
            PHYSICSPROCESSES[ self.name ] = self
    
    def _open( self, treeName ):
        # nothing to do
        pass
    
    @property 
    def crossSection( self ):
        ## Get the combined cross section in pb of all included datasets
        crossSection = 0.
        for dataset in self.datasets:
            crossSection += dataset.crossSection
        return crossSection
    
    @crossSection.setter 
    def crossSection( self, value ):
        if value is not None:
            self.logger.warning( 'crossSection: can not set cross section of %r' % self )
        pass
    
    @property
    def effectiveCrossSection(self):
        ## Get the effective cross section in pb including correction factors
        crossSection = 0.
        for dataset in self.datasets:
            crossSection += dataset.effectiveCrossSection
        return crossSection * self.getCombinedScaleFactors()
    
    
    @property
    def entries( self ):
        ## Get the combined entries of all included datasets
        entries = 0
        for dataset in self.datasets:
            entries += dataset.entries
        return entries
    
    @property
    def trueDatasets( self ):
        ## Get list of all contained datasets
        #  Recursively resolves all PhysicsProcess daughters, only returns Dataset objects
        datasets = []
        for dataset in self.datasets:
            datasets.extend( dataset.trueDatasets )
        return datasets
    
    @property
    def combinedSystematicsSet( self ):
        ## Get the combined SystematicsSet of this PhysicsProcess and all daughters
        result = set( self.systematicsSet )
        for dataset in self.datasets:
            result |= dataset.combinedSystematicsSet
        return result
    
    @property
    def preselection( self ):
        ## Get the current preselection that is applied
        for dataset in self.datasets:
            return dataset.preselection
    
    @preselection.setter
    def preselection( self, cut=Cut() ):
        ## Define a preselection for this dataset using the TEntryList functionality of TTree
        #  Use an empty cut to reset the preselection
        #  WARNING: this selection is always active even if a looser selection is drawn
        #  @param cut    the preselection cut to apply
        for dataset in self.datasets:
            dataset.preselection = cut
            
    @property
    def weightExpression( self ):
        ## Get the weight expression applied to this Dataset
        return self.__weightExpression
    
    @weightExpression.setter
    def weightExpression( self, expression ):
        ## Set the weight expression applied to this Dataset
        self.__weightExpression = expression
        for dataset in self.datasets:
            dataset.weightExpression = expression
    
    def addSystematics( self, systematics ):
        ## Add a Systematics object to all daughter Datasets
        for dataset in self.datasets:
            dataset.addSystematics( systematics )
        
    def removeSystematics( self, systematics ):
        ## Remove a Systematics object from this Dataset
        self.systematicsSet.discard( systematics )
        for dataset in self.datasets:
            dataset.removeSystematics( systematics )
    
    def addFriendTree( self, friendTree ):
        ## Add a FriendTree object to all contained datasets
        for dataset in self.datasets:
            dataset.addFriendTree( friendTree )
    
    def save( self, directory='./', selection=None ):
        ## Stores all contained datasets in the given directory using the given preselection
        #  @param directory     name of the output directory. File names are "<dataset.name>.root"
        #  @param selection     event selection applied to the trees (default preselection if defined)
        for dataset in self.datasets:
            dataset.save( os.path.join( directory, dataset.name + '.root' ) )
    
    def getYield( self, cut=Cut(), weightExpression=None, luminosity=1., ignoreWeights=False, systematicVariation=None, ignoreDataWeight=False ):
        ## Calculate the expected yield for the given selection
        #  @param cut               Cut object that defines the applied cut
        #  @param weightExpression  weight expression (overrides the default weight expression)
        #  @param luminosity        global scale factor, i.e. integrated luminosity, not applied for data
        #  @param ignoreWeights     ignore the weights and any other scale factors including luminosity
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param ignoreDataWeight     used for fake-factor data-mc where weight is to be applied to data via self.weightExpression
        #  @return the yield
        totalYield = 0
        totalUncertainty = 0
        cut = self._determineCut( cut )
        for dataset in self.datasets:
            y, error = dataset.getYield( cut, weightExpression, luminosity, ignoreWeights, systematicVariation, ignoreDataWeight )
            totalYield += y
            totalUncertainty = math.sqrt( totalUncertainty**2 + error**2 )
        scaleFactor = self.getCombinedScaleFactors( systematicVariation )
        return totalYield * scaleFactor, totalUncertainty*scaleFactor
    
    def getValues( self, xVar, cut=None, weightExpression=None, luminosity=1., systematicVariation=None ):
        ## Gets the values and weights for a given variable and selection
        #  @param xVar                 Variable object defining which values should be calculated
        #  @param cut                  Cut object that defines the applied cut
        #  @param weightExpression     weight expression (overrides the default weight expression)
        #  @param luminosity           global scale factor, i.e. integrated luminosity, not applied for data
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param ignoreDataWeight     used for fake-factor data-mc where weight is to be applied to data via self.weightExpression
        #  @return (values, weights)
        import numpy
        values = numpy.empty( [0.] )
        weights = numpy.empty( [0.] )
        cut = self._determineCut( cut )
        for dataset in self.datasets:
            v, w = dataset.getValues( xVar, cut, weightExpression, luminosity, systematicVariation )
            values = numpy.append( values, v )
            weights = numpy.append( weights, w )
        return values, weights        
        
    def getHistogram( self, xVar, title=None, cut=None, weight=None, drawOption='', style=None, luminosity=1., recreate=False, systematicVariation=None, includeOverflowBins=False, ignoreDataWeight=False ):
        ## Get the combined histogram of all contained datasets
        #  @param xVar         Variable object that defines the variable expresseion used in draw and the binning
        #  @param title        defines the histogram title
        #  @param cut          TCut object that defines the applied cut
        #  @param weight       weight expression (overrides the default weight expression)
        #  @param drawOption   ROOT draw option
        #  @param style        Style object (overrides the default style object)
        #  @param luminosity   global scale factor, i.e. integrated luminosity
        #  @param recreate     force recreation of the histogram (don't read it from a possible histogram file)
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param ignoreDataWeight     used for fake-factor data-mc where weight is to be applied to data via self.weightExpression
        #  @return histogram
        self.logger.debug( 'getHistogram(): creating histogram for var=%r with cut=%r and syst=%r from %r' % (xVar, cut, systematicVariation, self) )
        
        title = title if title else self.title
        style = style if style else self.style
        cut = self._determineCut( cut )
        histogram = None
        for dataset in self.datasets:
            h = dataset.getHistogram( xVar, title, cut, weight, drawOption, style, luminosity, recreate, systematicVariation, includeOverflowBins, ignoreDataWeight )
            if not h:
                self.logger.warning( 'getHistogram(): no histogram created for: dataset=%r, var=%r, cut=%r' % ( dataset, xVar, cut ) )
                continue
            if not histogram:
                histogram = h
                histogram.SetTitle( title )
            else:
                histogram.Add( h )
        if histogram:
            if style:
                style.apply( histogram )
            histogram.Scale( self.getCombinedScaleFactors( systematicVariation ) )
        return histogram
    
    def getHistogram2D( self, xVar, yVar, title=None, cut=None, weight=None, style=None, luminosity=1., recreate=False, systematicVariation=None, profile=False ):
        ## Get the combined histogram of all contained datasets
        #  @param xVar         Variable object that defines the variable expression for x used in draw and the binning
        #  @param yVar         Variable object that defines the variable expression for y used in draw and the binning
        #  @param title        defines the histogram title
        #  @param cut          TCut object that defines the applied cut
        #  @param weight       weight expression (overrides the default weight expression)
        #  @param style        Style object (overrides the default style object)
        #  @param luminosity   global scale factor, i.e. integrated luminosity
        #  @param recreate     force recreation of the histogram (don't read it from a possible histogram file)
        #  @param systematicVariation  SytematicVariation object defining the tree name and potential additional weights
        #  @param profile      Decide if a TProfile should be created instead of a TH2
        #  @return histogram
        self.logger.debug( 'getHistogram2D(): creating histogram for var=%r with cut=%r and syst=%r from %r' % (xVar, cut, systematicVariation, self) )
        
        title = title if title else self.title
        style = style if style else self.style
        cut = self._determineCut( cut )
        histogram = None
        for dataset in self.datasets:
            h = dataset.getHistogram2D( xVar, yVar, title, cut, weight, style, luminosity, recreate, systematicVariation, profile )
            if not h:
                self.logger.warning( 'getHistogram2D(): no histogram created for: dataset=%r, xVar=%r, yVar=%r, cut=%r' % ( dataset, xVar, yVar, cut ) )
                continue
            if not histogram:
                histogram = h
                histogram.SetTitle( title )
            else:
                histogram.Add( h )
        if histogram:
            if style:
                style.apply( histogram )
            histogram.Scale( self.getCombinedScaleFactors( systematicVariation ) )
        return histogram
    
    def toString( self ):
        ## String representation used for persistency
        s = '%s; %s; %d; %g; ' % (self.name, self.title, self.style.lineColor, self.kFactor)
        for dataset in self.datasets:
            s += '%s, ' % dataset.name
        s = s.rstrip(', ')
        return s
    
def createCutflowPlot( datasets, cuts, luminosity=None, ignoreWeights=False ):
    ## Helper method to create a cutflow histogram. Stacked if a luminosity scaling is requested
    #  @param datasets       list of datasets to include
    #  @param cuts           list of cuts that define the cutflow
    #  @param luminosity     luminosity to scale to
    #  @param ignoreWeights  set if all weights should be ignored
    #  @return the plot object
    var = createCutFlowVariable( cuts=cuts )
    p = BasicPlot( 'Cutflow', var )
    p.showBinWidthY = False
    if luminosity:
        p.titles.append( '#scale[0.5]{#int}Ldt = %.2g fb^{-1}' % (luminosity / 1000.) )
    for dataset in datasets:
        p.addHistogram( dataset.getCutflowHistogram(cuts, luminosity, ignoreWeights), stacked=luminosity is not None )
    return p

def writeDatasetsToTextFile( fileName, datasets ):
    ## Helper method to persist dataset definition in a text file
    #  @param fileName    name of the output text file
    #  @param datasets    list of datasets to persist
    f = open( fileName, 'w' )
    f.write( '# Datasets\n' )
    f.write( '# name; title; treeName; color; crossSection; kFactor; fileName1, fileName2, ...\n' )
    for dataset in datasets:
        f.write( dataset.toString() + '\n' )
    f.close()
    
def readDatasetsFromTextFile( fileName, cls=Dataset ):
    ## Helper method to read dataset definitions from a text file
    #  @param fileName    name of the input text file
    #  @param cls         class to use to interpret the text file
    #  @return list of datasets
    f = open( fileName )
    datasets = []
    for line in f:
        line = line.lstrip().rstrip()
        if not line or line[0] in ['#', '/']:
            continue
        datasets.append( cls.fromString( line ) )
    f.close()
    return datasets

def writePhysicsProcessesToTextFile( fileName, physicsProcesses ):
    ## Helper method to persist physics processes definition in a text file
    #  @param fileName    name of the output text file
    #  @param datasets    list of physics processes to persist
    f = open( fileName, 'w' )
    f.write( '# PhysicsProcesses\n' )
    f.write( '# name; title; color; kFactor; dataset1, dataset2, ...\n' )
    for physicsProcess in physicsProcesses:
        f.write( physicsProcess.toString() + '\n' )
    f.close()

def readPhysicsProcessesFromFile( fileName, cls=PhysicsProcess ):
    ## Helper method to read physics process definitions from a text file
    #  @param fileName    name of the input text file
    #  @param cls         class to use to interpret the text file
    #  @return list of physics processes
    f = open( fileName )
    physicsProcesses = []
    for line in f:
        line = line.lstrip().rstrip()
        if not line or line[0] in ['#', '/']:
            continue
        physicsProcesses.append( cls.fromString( line ) )
    f.close()
    return physicsProcesses        


if __name__ == '__main__':
    from ROOT import TTree, TFile, TRandom3, TCut, kBlue, kRed
    from array import array
    from AtlasStyle import redLine, blueLine, greenLine, orangeLine
    from Variable import Binning, Variable
    from Systematics import Systematics
    
    #logging.root.setLevel( logging.DEBUG )
     
    # create some dummy trees in a dummy file
    f = TFile( 'temp.root', 'recreate' )
    rndm = TRandom3()
    mass1 = array( 'f', [0] )
    mass2 = array( 'f', [0] )
    mass3 = array( 'f', [0] )
    weight = array( 'f', [0] )
    t1 = TTree( 'tree1', 'tree1' )
    t2 = TTree( 'tree2', 'tree2' )
    t3 = TTree( 'tree3', 'tree3' )
    t1.Branch( 'mass', mass1, 'mass/F' )
    t1.Branch( 'weight', weight, 'weight/F' )
    t2.Branch( 'mass', mass2, 'mass/F' )
    t2.Branch( 'weight', weight, 'weight/F' )
    t3.Branch( 'mass', mass3, 'mass/F' )
    t3.Branch( 'weight', weight, 'weight/F' )
    sumOfWeights = 0.
    for entry in xrange( 10000 ):
        mass1[0] = rndm.Gaus( 5, 8 )
        mass2[0] = rndm.Gaus( 20, 5 )
        mass3[0] = rndm.Gaus( 15, 1 )
        weight[0] = rndm.Gaus( 1.2, 0.1 )
        sumOfWeights += weight[0]
        t1.Fill()
        t2.Fill()
        t3.Fill()
    f.Write()
    f.Close()
 
    # create the datasets
    dataset1 = Dataset( 'background1', 'Background 1', ['temp.root'], 'tree1', orangeLine, 'weight', crossSection=5.0 )
    dataset2 = Dataset( 'background2', 'Background 2', ['temp.root'], 'tree2', greenLine, 'weight', crossSection=1.0 )
    dataset3 = Dataset( 'signal', 'Signal', ['temp.root'], 'tree3', redLine, 'weight', crossSection=0.1 )
     
    # alternatively we can also build the physics process from a string representation
    # the format is "name; title; treeName; color; crossSection; kFactor; fileName1, fileName2, ... "
    dataset21 = Dataset.fromString( 'background21; Background 1; tree1; 801; 5.0; 1.0; temp.root' )
    dataset22 = Dataset.fromString( 'background22; Background 2; tree2; 417; 1.0; 1.0; temp.root' )
    dataset23 = Dataset.fromString( 'signal2; Signal; tree3; 632; 0.1; 1.0; temp.root' )
     
    # we can define a HistogramStore which will store all created histograms for faster recreation of plots with the same histograms
    Dataset.histogramStore = HistogramStore( 'hist.root' )
     
    # combine some datasets into a physics process
    backgrounds = PhysicsProcess( 'backgrounds', 'Background x 1.2', blueLine, datasets=[dataset1, dataset2] )
    # add another scale factor
    backgrounds.scaleFactors['rQCD'] = 1.2
    print backgrounds
     
    # alternatively we can also build the physics process from a string representation. The dataset objects with the referenced names have to exist before.
    # the format is "name; title; color; kFactor; dataset1, dataset2, ... "
    backgrounds2 = PhysicsProcess.fromString( 'backgrounds2; Background 2; 600; 1.0; background21, background22' )
    
    # manually set the sum of weights
    for dataset in [ dataset1, dataset2, dataset3, dataset21, dataset22, dataset23 ]:
        dataset.sumOfWeights = sumOfWeights
    
    # define the global lumi scaling in pb-1
    luminosity = 2500.
    
    # get the yield for a certain cut
    print 'Yield from "backgrounds" with "mass>5:"', backgrounds.getYield( Cut('mass > 5'), luminosity=luminosity )
    print 'Yield from "backgrounds" with "mass>15:"', backgrounds.getYield( Cut('mass > 15'), luminosity=luminosity )
     
    # create and draw a cut flow diagram for all datasets
    cutFlowPlot = createCutflowPlot( [dataset1, dataset2, dataset3], [Cut('', 'All Events' ), Cut('mass > 5', 'M > 5 GeV'), Cut('mass > 15', 'M > 15 GeV')], luminosity )
    cutFlowPlot.draw()
     
    # define a variable object for each branch
    massVar = Variable( 'mass', title='M', unit='GeV', binning=Binning(50, 0., 25.) )
     
    # define a generic preselection to improve performance
    backgrounds.preselection = Cut( 'mass > 2' )
    
    # create a plot using the BasicPlot class
    testPlot = BasicPlot( 'Dataset Test', massVar )
    # add background and signal datasets as stacked
    testPlot.addHistogram( backgrounds.getHistogram( massVar ), stacked=True )
    testPlot.addHistogram( dataset3.getHistogram( massVar ), stacked=True )
    # add lines to indicate the two background components (note that they are automatically weighed by their cross section)
    testPlot.addHistogram( dataset1.getHistogram( massVar ), drawOption='E0' )
    testPlot.addHistogram( dataset2.getHistogram( massVar ), drawOption='E0' )
    # draw the plot
    testPlot.draw()
    
    # example for including systematics
    systematicsPlot = BasicPlot( 'Systematics Test', massVar )
    # define a simple scale uncertainty +10%, -5%
    backgrounds.systematicsSet.add( Systematics.scaleSystematics( 'scaleSyst', upScale=1.1, downScale=0.95 ) )
    # add the nominal histogram with statistical uncertainties only
    h = backgrounds.getHistogram( massVar )
    s = backgrounds.getSystematicsGraph( massVar, 'Systematics', style=Style( kRed, fillStyle=3004 ) )
    systematicsPlot.addSystematicsGraph( h, s )
    systematicsPlot.addHistogram( h, 'E0' )
    systematicsPlot.combineStatsAndSyst = False
    systematicsPlot.draw()
    
    
    # example for a 2D histogram
    weightVar = Variable('weight', title='Weight', binning=Binning(20,0.7,1.7))
    plot2D = BasicPlot( '2D Test', massVar, weightVar )
    plot2D.addHistogram( backgrounds.getHistogram2D( massVar, weightVar, luminosity=1000 ), 'COLZ' )
    plot2D.draw()
    
     
    # Datasets and PhysicsProcesses can be persisted in text files
    writeDatasetsToTextFile( 'datasets.txt', DATASETS.values() )
    writePhysicsProcessesToTextFile( 'processes.txt', PHYSICSPROCESSES.values() )
    print 'Reading datasets from "datasets.txt":', readDatasetsFromTextFile( 'datasets.txt' )
    print 'Reading processes from "processes.txt":', readPhysicsProcessesFromFile( 'processes.txt' )
 
    raw_input( 'Continue?' )
     
    # clean up and delete temp file
    os.remove( 'temp.root' )
    os.remove( 'datasets.txt' )
    os.remove( 'processes.txt' )
    
